{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/airbnb_logo.png\"\n",
    "    style=\"width:300px; float: right; margin: 0 40px 40px 40px;\"></img>\n",
    "# Group Project AirBnB\n",
    "**Useful links**\n",
    "\n",
    "<a href=\"https://github.com/ShimantoRahman/aCRM-Group-Project-AirBnB\"><img src=\"./assets/github_logo.png\" style=\"width:120px; margin: 0 0 40px 40px;\"></a>\n",
    "\n",
    "> [Inside AirBnB: New York](http://insideairbnb.com/new-york-city/?fbclid=IwAR3lvDyNFboZqns1jNJ8v4OzqzG8sLFsqeSlRjqb_-tyvk4iM_XRSYdwmEQ)\n",
    "\n",
    "> [Airbnb Rental Listings Dataset Mining](https://towardsdatascience.com/airbnb-rental-listings-dataset-mining-f972ed08ddec)\n",
    "\n",
    "## 1 Setup\n",
    "### 1.1 Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import os\n",
    "import folium\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "!pip install -U textblob\n",
    "!pip install WordCloud\n",
    "!pip install folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](./assets/green_divider.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_detail = pd.read_csv(\"./data/calendar_detail.csv\")\n",
    "listings_summary = pd.read_csv(\"./data/listings_summary.csv\")\n",
    "reviews_summary = pd.read_csv(\"./data/reviews_summary.csv\")\n",
    "neighbourhoods = pd.read_csv(\"./data/neighbourhoods.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_detail = pd.read_csv(\"./data/listings_detail.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_detail = pd.read_csv(\"./data/reviews_detail.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install folium\n",
    "!pip install -U textblob\n",
    "!pip install WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_detail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhoods.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_detail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_detail.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](./assets/green_divider.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 data preparation\n",
    "#### 1.3.1 Detecting NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"listings_summary\\n\")\n",
    "print(listings_summary.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"listings_detail\\n\")\n",
    "print(listings_detail.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"reviews_summary\\n\")\n",
    "print(reviews_summary.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"reviews_detail\\n\")\n",
    "print(reviews_detail.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"neighbourhoods\\n\")\n",
    "print(neighbourhoods.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\ncalendar_detail\\n\")\n",
    "print(calendar_detail.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](./assets/green_divider.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Cleansing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing listings where first and last review do not both match\n",
    "listings_detail = listings_detail[~((listings_detail[\"first_review\"].isnull()) & ~(listings_detail[\"last_review\"].isnull()))]\n",
    "\n",
    "# removing reviews without a comment\n",
    "reviews_detail = reviews_detail.dropna(subset=['comments'])\n",
    "\n",
    "# removing listings without a superhost value\n",
    "listings_detail = listings_detail.dropna(subset=['host_is_superhost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing parallel rows in summary\n",
    "reviews_detail[reviews_detail[\"comments\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing NaN values for reviews_per_month to 0\n",
    "# rows with NaN value for reviews_per_month do not have a first or last review, thus they have 0 reviews per month\n",
    "column_imputations = {\"reviews_per_month\": 0}\n",
    "listings_detail = listings_detail.fillna(value = column_imputations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](./assets/green_divider.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Correcting data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates\n",
    "def column_to_date(df, column):\n",
    "    df[column] = pd.to_datetime(df[column], format=\"%Y-%m-%d\")\n",
    "    \n",
    "# listings_summary\n",
    "column_to_date(listings_summary, \"last_review\")\n",
    "\n",
    "# reviews_summary\n",
    "column_to_date(reviews_summary, \"date\")\n",
    "\n",
    "# calendar_detail\n",
    "column_to_date(calendar_detail, \"date\")\n",
    "\n",
    "# listings_detail\n",
    "column_to_date(listings_detail, \"first_review\")\n",
    "column_to_date(listings_detail, \"last_review\")\n",
    "column_to_date(listings_detail, \"last_scraped\")\n",
    "column_to_date(listings_detail, \"calendar_last_scraped\")\n",
    "column_to_date(listings_detail, \"host_since\")\n",
    "\n",
    "# reviews_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change t/f columns to 1/0\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "def column_to_bool(df, column):\n",
    "    label_encoder.fit(df[column])\n",
    "    new_column = column + \"_num\"\n",
    "    df[new_column] = label_encoder.transform(df[column])\n",
    "\n",
    "column_to_bool(listings_detail, \"instant_bookable\")\n",
    "column_to_bool(listings_detail, \"requires_license\")\n",
    "column_to_bool(listings_detail, \"is_business_travel_ready\")\n",
    "column_to_bool(listings_detail, \"require_guest_profile_picture\")\n",
    "column_to_bool(listings_detail, \"require_guest_phone_verification\")\n",
    "column_to_bool(listings_detail, \"instant_bookable\")\n",
    "# column_to_bool(listings_detail, \"host_is_superhost\")\n",
    "column_to_bool(listings_detail, \"has_availability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change categorical columns to numerical labels\n",
    "def column_to_numeric_labels(df, column):\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(df[column])\n",
    "    df[column + \"_num\"] = label_encoder.transform(df[column])\n",
    "\n",
    "column_to_numeric_labels(listings_summary, \"neighbourhood_group\")\n",
    "column_to_numeric_labels(listings_summary, \"neighbourhood\")\n",
    "column_to_numeric_labels(listings_summary, \"room_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing price from $00.0 [String] to 00.0 float \n",
    "\n",
    "calendar_detail[\"price\"] = calendar_detail[\"price\"].str.replace(\"$\", \"\")\n",
    "calendar_detail[\"price\"] = calendar_detail[\"price\"].str.replace(\",\", \"\")\n",
    "calendar_detail[\"price\"] = pd.to_numeric(calendar_detail[\"price\"])\n",
    "\n",
    "listings_detail[\"price\"] = listings_detail[\"price\"].str.replace(\"$\", \"\")\n",
    "listings_detail[\"price\"] = listings_detail[\"price\"].str.replace(\",\", \"\")\n",
    "listings_detail[\"price\"] = pd.to_numeric(listings_detail[\"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](./assets/green_divider.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Analysis\n",
    "### 2.1 Calculate the average listing price per neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(listings_summary.groupby(\"neighbourhood\").mean()[\"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Plot how the average price evolves through the year across New York.\n",
    "<span style=\"color:red\"> **TODO:** investigate peaks and prices weekdays vs prices weekends</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn plot using plot()\n",
    "calendar_detail[[\"date\", \"price\"]].groupby(\"date\").mean().plot()\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average price\")\n",
    "plt.title(\"Average price across the year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn plot using explicit seaborn function\n",
    "avg_price_day = calendar_detail[[\"date\", \"price\"]].groupby(\"date\").mean()\n",
    "avg_price_day['date'] = avg_price_day.index\n",
    "avg_price_day.head()\n",
    "\n",
    "sns.lineplot(x = \"date\", y = \"price\", data = avg_price_day)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average price\")\n",
    "plt.title(\"Average price across the year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median instead of mean\n",
    "calendar_detail[[\"date\", \"price\"]].groupby(\"date\").median().plot()\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average price\")\n",
    "plt.title(\"Average price across the year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3\tIdentify which neighborhood has the largest price fluctuations across the year. Plot the fluctuations for this neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining listings_summary with calendar_detail\n",
    "cal_listing = pd.merge(calendar_detail, listings_summary[[\"id\", \"neighbourhood\"]], how=\"inner\", left_on=\"listing_id\", right_on = \"id\")\n",
    "cal_listing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating variance per neighbourhood and requesting top one\n",
    "price_by_neighbourhood = cal_listing[[\"neighbourhood\", \"price\"]].groupby(\"neighbourhood\").var().reset_index()\n",
    "nb_with_largest_var = price_by_neighbourhood.sort_values(\"price\", ascending = False).iloc[0][\"neighbourhood\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the prices of the neighbourhood with the largest price fluctuations\n",
    "cal_listing[[\"date\", \"price\", \"neighbourhood\"]][cal_listing[\"neighbourhood\"] == nb_with_largest_var].groupby(\"date\").mean().plot()\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average price\")\n",
    "plt.title(\"Average price in neighbourhood with largest price fluctuations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 In marketing, there is a phenomenon known as ‘the long tail’ (Hint: look it up). This also translates to the number of reviews. Plot this on an intuitive graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition\n",
    "**The long tail** is a business strategy that allows companies to realize significant profits \n",
    "by selling low volumes of hard-to-find items to many customers, \n",
    "instead of only selling large volumes of a reduced number of popular items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot reviews per listings VS listings per host\n",
    "\n",
    "# compute reviews per listing\n",
    "temp = listings_summary[[\"host_id\", \"calculated_host_listings_count\"]]\n",
    "agg_dict = {\"number_of_reviews\":sum}\n",
    "id_reviews = listings_summary.groupby(\"host_id\").agg(agg_dict).reset_index().rename(columns={\"number_of_reviews\": \"total_number_of_reviews\"})\n",
    "host_count_reviews = temp.merge(id_reviews, how = \"right\", on = \"host_id\")\n",
    "\n",
    "host_count_reviews[\"reviews_per_listing\"] = host_count_reviews[\"total_number_of_reviews\"] / (host_count_reviews[\"calculated_host_listings_count\"])\n",
    "host_count_reviews.sort_values(by = \"calculated_host_listings_count\", ascending = False)\n",
    "host_count_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "sns.scatterplot(x = \"calculated_host_listings_count\", y = \"reviews_per_listing\", alpha = 0.2, data = host_count_reviews)\n",
    "plt.xlabel(\"Listings per host\")\n",
    "plt.ylabel(\"Reviews per listing\")\n",
    "plt.title(\"'The long tail'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5\tRun a regression to explain the price per listing. (Hint: location, reviews, etc. may all explain this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import  LinearRegression\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X = listings_summary[[\"neighbourhood_group_num\", \"neighbourhood_num\", \"room_type_num\", \"minimum_nights\", \n",
    "                                   \"number_of_reviews\", \"reviews_per_month\", \"availability_365\"]], y = listings_summary[\"price\"])\n",
    "price_est = lr_model.predict(listings_summary[[\"neighbourhood_group_num\", \"neighbourhood_num\", \"room_type_num\", \"minimum_nights\", \n",
    "                                   \"number_of_reviews\", \"reviews_per_month\", \"availability_365\"]])\n",
    "\n",
    "print(lr_model.intercept_)\n",
    "print(lr_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "price_true = listings_summary[\"price\"]\n",
    "mse = mean_squared_error(price_true, price_est)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Find additional data sources to explain the average listing price per neighbourhood. (Hint : think demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Plot how the average prices differ across New York using a color-coded heat map of New York neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean prices per neighbourhood\n",
    "price_data = listings_summary[[\"neighbourhood\", \"price\"]].groupby(\"neighbourhood\").mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read geojson\n",
    "with open('./data/neighbourhoods.geojson') as json_file:\n",
    "    geo_json_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot map\n",
    "m = folium.Map([40.6976637, -74.1197643], tiles='cartodbpositron', zoom_start=10)\n",
    "\n",
    "m.choropleth(\n",
    "    geo_data= geo_json_data,\n",
    "    name='choropleth',\n",
    "    data= price_data,\n",
    "    columns=['neighbourhood', 'price'],\n",
    "    key_on='properties.neighbourhood',\n",
    "    fill_color='YlGn',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name='Average price'\n",
    ")\n",
    "\n",
    "m.save(\"./assets/graphs/prices.html\")\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 The latitude of Statue of Liberty National Monument, New York, USA is 40.68927, and the longitude is -74.044502. This monument is one of the most popular tourist places in New York. Statistically test wether a distance smaller than 2 miles to the monument increases average listing price.\n",
    "[Stackoverflow](https://stackoverflow.com/questions/19412462/getting-distance-between-two-points-based-on-latitude-longitude): calculate distance between 2 points based on longitude and latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "# approximate radius of earth in km\n",
    "R = 6373.0\n",
    "\n",
    "lat1 = radians(52.2296756)\n",
    "lon1 = radians(21.0122287)\n",
    "lat2 = radians(52.406374)\n",
    "lon2 = radians(16.9251681)\n",
    "\n",
    "dlon = lon2 - lon1\n",
    "dlat = lat2 - lat1\n",
    "\n",
    "a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "distance = R * c\n",
    "\n",
    "print(\"Result:\", distance)\n",
    "print(\"Should be:\", 278.546, \"km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9\tCreate a timeline and plot for each month the highest, Q1, the median, Q3 and lowest price on one graph. Do this for each neighborhood group as well as for the entire city. Determine which neighborhood group stands out the most and create a comparative graph of this neighborhood with all other groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 Plot the number of rooms per host in function of the number of reviews per host. \n",
    "#### Method 1 (manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute number of listings and total number of reviews per host\n",
    "agg_dict = {\"id\":len, \"number_of_reviews\":sum}\n",
    "id_reviews = listings_summary.groupby(\"host_id\").agg(agg_dict).reset_index()\n",
    "\n",
    "sns.scatterplot(x = \"id\", y = \"number_of_reviews\", alpha = 0.4, data = id_reviews) # add jitter?\n",
    "plt.xlabel(\"Total number of rooms per host\")\n",
    "plt.ylabel(\"Total number of reviews per host\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2 (with calculated_host_listings_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {\"number_of_reviews\":sum}\n",
    "temp = listings_summary.groupby(\"host_id\").agg(agg_dict).reset_index()\n",
    "\n",
    "id_reviews_2 = listings_summary[[\"host_id\", \"calculated_host_listings_count\"]].merge(temp, how = \"right\", on = \"host_id\")\n",
    "\n",
    "sns.scatterplot(x = \"calculated_host_listings_count\", y = \"number_of_reviews\", alpha = 0.4, data = id_reviews_2) # add jitter?\n",
    "plt.xlabel(\"Total number of rooms per host\")\n",
    "plt.ylabel(\"Total number of reviews per host\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> CODE DOES NOT WORK YET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to add jitter to scatterplot but does not work\n",
    "def rand_jitter(arr):\n",
    "    stdev = .01*(max(arr)-min(arr))\n",
    "    return arr + np.random.randn(len(arr)) * stdev\n",
    "\n",
    "def jitter(x, y, s=20, c='b', marker='o', cmap=None, norm=None, vmin=None, vmax=None, alpha=None, linewidths=None, verts=None, hold=None, **kwargs):\n",
    "    return sns.scatterplot(rand_jitter(x), rand_jitter(y), s=s, c=c, marker=marker, cmap=cmap, norm=norm, vmin=vmin, vmax=vmax, alpha=alpha, linewidths=linewidths, verts=verts, hold=hold, **kwargs)\n",
    "\n",
    "jitter(x = id_reviews[\"id\"], y = id_reviews[\"number_of_reviews\"], alpha = 0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.11 Are there a lot of hosts having multiple locations? Do most people just rent their own place? Is there a ‘host long tail’? Make a comprehensive plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.12 Do hosts with multiple locations stay within the same neighbourhood? (hint: use subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating:\n",
    "# number of hosts with multiple locations\n",
    "# number of hosts with multiple locations in different neighbourhoods\n",
    "# number of hosts with multiple locations in the same neighbourhood\n",
    "\n",
    "mult_loc = listings_summary[[\"id\", \"host_id\"]].groupby(\"host_id\").apply(lambda x: 1 if len(x) > 1 else 0).sum()\n",
    "mult_loc_diff_nb = listings_summary[[\"host_id\", \"neighbourhood\"]].groupby(\"host_id\").apply(lambda x: 1 if len(x[\"neighbourhood\"].unique()) > 1 else 0).sum()\n",
    "mult_loc_same_nb = mult_loc - mult_loc_diff_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mult_loc)\n",
    "print(mult_loc_diff_nb)\n",
    "print(mult_loc_same_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot\n",
    "plt.bar([\"Same neighbourhood\", \"Different neighbourhood\"], [mult_loc_same_nb, mult_loc_diff_nb])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.13 What are the 5 most used words in reviews that are no stop words? (e.g. the, or, etc. Python can filter these automatically using packages such as NLTK).\n",
    "#### NLTK data prep\n",
    "> read text_analysis.csv instead, because some steps like tokenizing take very long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_detail[\"comments_length\"]= reviews_detail[\"comments\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_detail[\"comments_length\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_detail[reviews_detail[\"comments_length\"]==1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing comments with just a space or a dot\n",
    "text_analysis = reviews_detail[reviews_detail['comments']!=' ']\n",
    "text_analysis = text_analysis[text_analysis['comments']!='.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning every comment to lower case\n",
    "text_analysis[\"comments\"] = text_analysis[\"comments\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting how many times a review has been posted\n",
    "review_counts = text_analysis.comments.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request top 20 most common comments\n",
    "# A lot of the reviews are automated posts\n",
    "review_counts[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing automated posts\n",
    "text_analysis = text_analysis[text_analysis[\"comments\"].str.find(\"this is an automated posting.\") == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recounting how many times a review has been posted\n",
    "review_counts = text_analysis.comments.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request top 20 most common comments\n",
    "review_counts[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits comments into tokens (takes a while)\n",
    "text_analysis['tokenized_comments'] = text_analysis.apply(lambda row: nltk.word_tokenize(row['comments']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the words in every comment\n",
    "text_analysis['word_count'] = [ len(words) for words in text_analysis['tokenized_comments'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stop words and punctuation from the tokens\n",
    "filter_tokens = set(stopwords.words('english'))\n",
    "filter_tokens.update({\".\", \"?\", \"!\", \",\", \";\", \":\", \"(\", \")\", \"{\", \"}\", \"[\", \"]\"})\n",
    "\n",
    "# other not useful words\n",
    "filter_tokens.update({\"'s\", \"would\", \"de\", \"n't\", \"us\"})\n",
    "\n",
    "text_analysis['tokenized_filtered'] = text_analysis['tokenized_comments'].apply(lambda x: [item for item in x if item not in filter_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write text_analysis to csv\n",
    "text_analysis[[\"id\", \"comments_length\", \"tokenized_filtered\", \"word_count\"]].to_csv(\"./data/text_analysis.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "text_analysis = pd.read_csv(\"./data/text_analysis.csv\")\n",
    "text_analysis[\"tokenized_filtered\"] = text_analysis[\"tokenized_filtered\"].apply(lambda x: x[2:-2].split('\\', \\''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores 100 most common words\n",
    "flat_list = [item for sublist in text_analysis[\"tokenized_filtered\"] for item in sublist]\n",
    "most_common_words = Counter(flat_list).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests 5 most common words\n",
    "most_common_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word cloud\n",
    "# NOT COMPLETE\n",
    "from wordcloud import WordCloud\n",
    "amount = np.array([x[1] for x in most_common_words])\n",
    "normalized_amount = np.round(((amount / amount[0]) * 100))\n",
    "text = \"\"\n",
    "for i in range(0, len(most_common_words)):\n",
    "    for j in range(0, int(normalized_amount[i])):\n",
    "        text += \" \" + most_common_words[i][0]\n",
    "        \n",
    "wordcloud = WordCloud(width=480, height=480, margin=0).generate(text[1:])\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.margins(x=0, y=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    " \n",
    "# Create a list of word\n",
    "text=(\"Python Python Python Matplotlib Matplotlib Seaborn Network Plot Violin Chart Pandas Datascience Wordcloud Spider Radar Parrallel Alpha Color Brewer Density Scatter Barplot Barplot Boxplot Violinplot Treemap Stacked Area Chart Chart Visualization Dataviz Donut Pie Time-Series Wordcloud Wordcloud Sankey Bubble\")\n",
    " \n",
    "# Create the wordcloud object\n",
    "wordcloud = WordCloud(width=480, height=480, margin=0).generate(text)\n",
    " \n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.margins(x=0, y=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating sentiment for every review\n",
    "reviews_detail[\"sentiment\"] = reviews_detail[\"comments\"].apply(lambda x: TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_detail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average sentiment per listing\n",
    "# adds sentiments to the listings_summary\n",
    "sentiments = reviews_detail[[\"listing_id\", \"sentiment\"]].groupby(\"listing_id\").mean().reset_index()\n",
    "listings_summary = pd.merge(listings_summary, sentiments, how = \"left\", left_on = \"id\", right_on = \"listing_id\")\n",
    "listings_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.14 Do these most frequent words differ across neighborhoods? What are the ‘most different’ areas? What distinguishes them? Interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perhaps areas near monuments have those in its 'most frequest words' list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.15 Plot the amount of reviews across time. \n",
    "#### Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of reviews per date\n",
    "rev_per_date = reviews_summary.groupby(\"date\").size().reset_index(name=\"counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17, 6))\n",
    "plt.plot(rev_per_date[\"date\"], rev_per_date[\"counts\"])\n",
    "plt.title(\"Amount of reviews across time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Amount of reviews\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregating results by year\n",
    "rev_per_date['year'] = [t.year for t in rev_per_date.date]\n",
    "rev_per_year = rev_per_date.groupby(\"year\").sum().reset_index()\n",
    "rev_per_year[\"year\"] = pd.to_datetime(rev_per_year[\"year\"], format=\"%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17, 6))\n",
    "plt.plot(rev_per_year[\"year\"], rev_per_year[\"counts\"])\n",
    "plt.title(\"Amount of reviews across time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Amount of reviews\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.16 Is there a link between availability (days per year) with the price? Determine both graphically and statistically. \n",
    "#### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(listings_detail[\"price\"], listings_detail[\"availability_365\"])[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression\n",
    "${Price_i} = \\alpha + \\beta \\thinspace Availability.365_{i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X=listings_detail[[\"availability_365\"]], y=listings_detail[\"price\"])\n",
    "price_est = lr_model.predict(listings_detail[[\"availability_365\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(listings_detail[\"availability_365\"], listings_detail[\"price\"])\n",
    "plt.plot(listings_detail[\"availability_365\"], price_est, \"-\", color=\"red\", label=\"predicted y\")\n",
    "plt.xlabel(\"Days listing is available per year\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.17 Is there a link between how many times the word ‘great’ appears in a review and the listing price? Determine both graphically and statistically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many times 'great' is mentioned in a review\n",
    "reviews_detail[\"times_great_in_comments\"]= reviews_detail[\"comments\"].str.lower().str.count(\"great\")\n",
    "\n",
    "# group every review with the same listing id together and add up how many times 'great' is mentioned\n",
    "times_great = reviews_detail[[\"listing_id\", \"times_great_in_comments\"]].groupby(by = \"listing_id\").sum()\n",
    "\n",
    "# join with listings_summary to get price of the listing\n",
    "times_great_listings = pd.merge(times_great, listings_summary[[\"id\", \"price\"]], how=\"inner\", left_on=\"listing_id\", right_on = \"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear correlation\n",
    "np.corrcoef(times_great_listings[\"price\"], times_great_listings[\"times_great_in_comments\"])[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression\n",
    "${Price_i} = \\alpha + \\beta \\thinspace Times.Great_{i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X=times_great_listings[[\"times_great_in_comments\"]], y=times_great_listings[\"price\"])\n",
    "price_est = lr_model.predict(times_great_listings[[\"times_great_in_comments\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = times_great_listings[\"times_great_in_comments\"], y = times_great_listings[\"price\"], alpha = 0.2)\n",
    "plt.plot(times_great_listings[\"times_great_in_comments\"], price_est, \"-\", color=\"red\", label=\"predicted y\")\n",
    "\n",
    "plt.xlabel(\"amount that great is mentioned in review\")\n",
    "plt.ylabel(\"price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.18 Plot how the number of Airbnb locations are distributed across the city on a map. Plot the number of locations per neighborhood and color code according to neighborhood group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculating the listings per neighbourhood\n",
    "listings_per_nb = listings_summary[[\"id\", \"neighbourhood\", \"neighbourhood_group\"]].groupby(by = [\"neighbourhood\", \"neighbourhood_group\"]).size().reset_index(name=\"counts\")\n",
    "long_lat_per_nb = listings_summary[[\"neighbourhood\", \"longitude\", \"latitude\"]].groupby(by = \"neighbourhood\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geomap\n",
    "m = folium.Map([40.6976637, -74.1197643], tiles='cartodbpositron', zoom_start=10)\n",
    "# location=[float(long_lat_per_nb.iloc[i]['longitude']), float(long_lat_per_nb.iloc[i]['latitude'])],\n",
    "\n",
    "for i in range(0,len(listings_per_nb)):\n",
    "    nbg = listings_per_nb.iloc[i]['neighbourhood_group']\n",
    "    col = \"\"\n",
    "    if nbg == \"Queens\":\n",
    "        col = \"#F23D4C\"\n",
    "    elif nbg == \"Bronx\":\n",
    "        col = \"#735571\"\n",
    "    elif nbg == \"Brooklyn\":\n",
    "        col = \"#04BFBF\"\n",
    "    elif nbg == \"Staten Island\":\n",
    "        col = \"#C6D93B\"\n",
    "    else:\n",
    "        col = \"#F2B705\"\n",
    "        \n",
    "    folium.Circle(\n",
    "      location=[float(long_lat_per_nb.iloc[i]['latitude']), float(long_lat_per_nb.iloc[i]['longitude'])],\n",
    "      popup=listings_per_nb.iloc[i]['neighbourhood'],\n",
    "      radius=int(listings_per_nb.iloc[i]['counts']),\n",
    "      color=col,\n",
    "      fill=True,\n",
    "      fill_color=col\n",
    "    ).add_to(m)\n",
    "\n",
    "# legend\n",
    "legend_html =   '''\n",
    "                <div style=\"position: fixed; \n",
    "                            bottom: 50px; left: 50px; width: 130px; height: 160px; \n",
    "                            border:2px solid grey; z-index:9999; font-size:14px;\n",
    "                            background-color: rgba(242, 243, 245, 0.5)\n",
    "                            \">\n",
    "                              &nbsp; Queens &nbsp; <i class=\"fa fa-map-marker fa-2x\" style=\"color:#F23D4C\"></i><br>\n",
    "                              &nbsp; Bronx &nbsp; <i class=\"fa fa-map-marker fa-2x\" style=\"color:#735571\"></i><br>\n",
    "                              &nbsp; Brooklyn &nbsp; <i class=\"fa fa-map-marker fa-2x\" style=\"color:#04BFBF\"></i><br>\n",
    "                              &nbsp; Staten Island &nbsp; <i class=\"fa fa-map-marker fa-2x\" style=\"color:#C6D93B\"></i><br>\n",
    "                              &nbsp; Manhattan &nbsp; <i class=\"fa fa-map-marker fa-2x\" style=\"color:#F2B705\"></i>\n",
    "                </div>\n",
    "                ''' \n",
    "\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "m.save(\"./assets/graphs/listings.html\")\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.19 Williamsburg is a ‘hip’ area in in Brooklyn with a lot of Airbnb locations on offer. Explore how this area differs from other locations and visualize. You may also use external data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot prices between different neighbourhood groups + williamsburg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.20  Create a stacked bar chart of the distribution of room type per neighborhood group. Statistically test whether these differences are significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts the number of room types for each neighbourhood group\n",
    "df = listings_summary[[\"room_type\", \"neighbourhood_group\"]].groupby([\"neighbourhood_group\", \"room_type\"]).size().reset_index(name=\"counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(df.groupby(\"neighbourhood_group\").sum().reset_index()[\"counts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(df)):\n",
    "    if df[\"neighbourhood_group\"].iloc[i] == \"Bronx\":\n",
    "        df[\"counts\"].iloc[i] = df[\"counts\"].iloc[i] / a[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked bar chart\n",
    "\n",
    "# x\n",
    "nbg = df[\"neighbourhood_group\"].unique()\n",
    "\n",
    "# y\n",
    "bars1 = df[df[\"room_type\"] == \"Entire home/apt\"][\"counts\"]\n",
    "bars1\n",
    "bars2 = df[df[\"room_type\"] == \"Private room\"][\"counts\"]\n",
    "bars3 = df[df[\"room_type\"] == \"Shared room\"][\"counts\"]\n",
    "\n",
    "# Staten Island has no shared rooms\n",
    "# manually add 0 for shared rooms in staten island\n",
    "# refactor later\n",
    "bars3 = bars3.append(pd.Series([0]))\n",
    "\n",
    "# bottoms\n",
    "bottom2 = bars1\n",
    "bottom3 = np.add(bars1, bars2).tolist()\n",
    "\n",
    "# draw bars\n",
    "plt.bar(nbg, bars1, label = \"Entire home\")\n",
    "plt.bar(nbg, bars2, bottom = bottom2, label = \"Private room\")\n",
    "plt.bar(nbg, bars3, bottom = bottom3, label = \"Shared room\")\n",
    "\n",
    "# legend\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(bars1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.21 Color-coded plot the most popular room type per neighborhood on a city map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute most popular room_type per neighbourhood\n",
    "distr_room_type = listings_summary[[\"neighbourhood\", \"room_type\"]].groupby(\"neighbourhood\")[\"room_type\"].value_counts(normalize = True).rename(\"percentage\").mul(100).reset_index()\n",
    "\n",
    "agg_dict = {\"percentage\":np.max}\n",
    "temp = distr_room_type.groupby(\"neighbourhood\").agg(agg_dict)\n",
    "\n",
    "popular_room_type = distr_room_type.merge(temp, how = \"right\", on = [\"neighbourhood\",\"percentage\"])\n",
    "print(popular_room_type.head())\n",
    "\n",
    "# merge together with listings_summary to get latitude and longitude\n",
    "# listings_room_type = listings_summary[[\"neighbourhood\", \"latitude\", \"longitude\"]].merge(popular_room_type, how = \"inner\", on = \"neighbourhood\")\n",
    "# listings_room_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_types_per_nb.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most popular room types per neighbourhood\n",
    "room_types_per_nb = listings_summary[[\"room_type\", \"neighbourhood\"]].groupby([\"neighbourhood\", \"room_type\"]).size().reset_index(name=\"counts\")\n",
    "# g = room_types_per_nb['counts'].groupby(level=0, group_keys=False)\n",
    "# g.apply(lambda x: x.order(ascending=False).head(3))\n",
    "# room_types_per_nb.sort_values(['neighbourhood','room_type'],ascending=False).groupby('neighbourhood').head(1)\n",
    "room_types_per_nb.groupby(\"neighbourhood\")[\"counts\"].nlargest(1)\n",
    "#[\"counts\"].nlargest(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/neighbourhoods.geojson') as json_file:\n",
    "    geo_json_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shared room: red, private room: yellow, entire home: green\n",
    "def my_color_function(feature):\n",
    "    if feature['properties']['neighbourhood'] not in listings_summary[\"neighbourhood\"].unique():\n",
    "        return \"#d3d3d3\"\n",
    "    room = popular_room_type[popular_room_type[\"neighbourhood\"] == feature['properties']['neighbourhood']][\"room_type\"]\n",
    "    a = room.to_string().split()\n",
    "    room = \" \".join(a[1:])\n",
    "    if room == \"Shared room\":\n",
    "        return '#ff0000'\n",
    "    elif room == \"Private room\":\n",
    "        return '#ffff00'\n",
    "    else:\n",
    "        return '#008000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map([40.6976637, -74.1197643], tiles='cartodbpositron', zoom_start=10)\n",
    "\n",
    "folium.GeoJson(\n",
    "    geo_json_data,\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': my_color_function(feature),\n",
    "        'color': 'black',\n",
    "        'weight': 1,\n",
    "        'dashArray': '5, 5',\n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "# legend\n",
    "legend_html =   '''\n",
    "                <div style=\"position: fixed; \n",
    "                            bottom: 50px; left: 50px; width: 200px; height: 100px; \n",
    "                            border:2px solid grey; z-index:9999; font-size:14px;\n",
    "                            background-color: rgba(242, 243, 245, 0.5)\n",
    "                            \">\n",
    "                              &nbsp; Entire home/apartment &nbsp; <i class=\"fa fa-map-marker fa-2x\" style=\"color:green\"></i><br>\n",
    "                              &nbsp; Private room &nbsp; <i class=\"fa fa-map-marker fa-2x\" style=\"color:yellow\"></i><br>\n",
    "                              &nbsp; Shared room &nbsp; <i class=\"fa fa-map-marker fa-2x\" style=\"color:red\"></i>\n",
    "                </div>\n",
    "                ''' \n",
    "\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "m.save(\"./assets/graphs/room_type.html\")\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
